{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines - is a model that can do both classification and \n",
    "prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"svm1.png\", width=300, height=200>\n",
    "\n",
    "References: https://commons.wikimedia.org/wiki/File:SVM_Example_of_Hyperplanes.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at another example\n",
    "\n",
    "<img src=\"svm2.png\" width=300, height=200>\n",
    "\n",
    "https://commons.wikimedia.org/wiki/File:SVM_margin.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vectors are the points that lie close to the decision boundary. \n",
    "\n",
    "The dataset will comprise of $(x_i, y_i)$ where $y_i$ is either 1 or -1 \n",
    "that indicates the class that $x_i$ belongs.\n",
    "\n",
    "Our goal is to find a hyperplane that separates the two classes with maximum margin. This hyperplane can be represented by \n",
    "$\\vec{w}\\vec{x} - \\vec{b} = 0.$\n",
    "\n",
    "Using the training dataset, we compute $\\vec{w}$ and $\\vec{b}.$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any point that lies on or above \n",
    "\n",
    "$\\vec{w}\\vec{x} - \\vec{b} = 1$ will be classified as class 1 \n",
    "and any point thay lies on or below\n",
    "\n",
    "$\\vec{w}\\vec{x} - \\vec{b} = -1$ will be classified as \n",
    "class 2.\n",
    "\n",
    "The distance between the two hyperplanes is $\\frac{2}{||\\vec{w}||},$ we want to maximize this which is same as minimizing $||\\vec{w}||.$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Hard-margin, we are very particular about the margin. No data points can lie within the margin. So hard-margins are narrow.\n",
    "\n",
    "In Soft-margin, data points can lie within the margin. Soft-margins are wide. \n",
    "\n",
    "The loss function for SVM is defined by\n",
    "$max(0, 1-y_i(\\vec{w}.\\vec{x_i} - b))$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bill_authentication.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Trick\n",
    "\n",
    "\n",
    "References: http://www.eric-kim.net/eric-kim-net/posts/1/kernel_trick.html\n",
    "\n",
    "https://prateekvjoshi.com/2012/09/01/kernel-functions-for-machine-learning/\n",
    "\n",
    "<img src=\"kernel1.png\", width=400, height=300>\n",
    "\n",
    "\n",
    "<img src=\"kernel3.jpg\", width=400, height=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different kernel functions\n",
    "\n",
    "References: https://www.slideshare.net/okamoto-laboratory/families-of-triangular-norm-based-kernel-function-and-its-application-to-kernel-kmeans-conference\n",
    "\n",
    "<img src=\"kernel2.png\", width=400, height=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When to use which kernel?\n",
    "\n",
    "Use linear SVM for linear problems and non-linear kernels such as RBF for non-linear data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider SVM with kernel trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "\n",
    "# Assign colum names to the dataset\n",
    "colnames = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
    "\n",
    "# Read dataset to pandas dataframe\n",
    "irisdata = pd.read_csv(url, names=colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = irisdata.drop('Class', axis=1)\n",
    "y = irisdata['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polynomial kernel\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='poly', degree=4)\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guassian kernel\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='rbf')\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
